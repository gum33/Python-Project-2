{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Instruction\n",
    "\n",
    "- Please rename this file so that you know which copy you have been working in. Keep a copy safe (especially if you are working in the online Jupyter service), for instance you could store your work on GitLab. You can download a copy by choosing -File- then -Download as- Notebook from the menu above. \n",
    "- Make sure your code is readable, organised, and commented appropriately.\n",
    "\n",
    "\n",
    "## Team working \n",
    "\n",
    "Firstly agree amongst yourself how you are to work together as a group. \n",
    "- When will you meet? or will you work remotely from each other?\n",
    "- How are you going to share code?\n",
    "- How will you divide tasks?\n",
    "- Who will present the final notebook, who will upload?\n",
    "- When are you planning to work on the project?\n",
    "\n",
    "The following tasks are all open-ended, so you should plan to work on them and investigate the problems raised and think about what you wish to cover. Because the task is open-ended you don't need to talk about every aspect of the problem to get a good mark - you should aim to present a coherent and well coded investigation into some aspects of each task though. The listed questions are a guide to some things you could think about to get you started, you don't need to answer them all, and you can certainly answer questions that are not listed.\n",
    "\n",
    "When you are presenting your investigation of each problem, be sure to make a coherent discussion for each task (using markdown, maths as appropriate and code cells). In particular, since you are working as a group some work will be needed to make a single written response to the task combining all of the code and writing that you each contribute - this is something that you should plan to do and the quality of presentation will be marked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Analysing the product reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you are supposed to analyse product reviews and extract helpful information from them. The case we are studying here is the review dataset of women’s clothes that are sold by a company online. In the file `WomensApparelReviews.csv`, you are given over 23000 reviews that are real but anonymized. The columns of this dataset are the following variables:\n",
    "\n",
    "\n",
    "**Product ID**: integer variable that refers to the specific item that is reviewed.\n",
    "\n",
    "**Age**: the reviewers age.\n",
    "\n",
    "**Title**: the title picked by the reviewer (some reviewers didn't pick any titles).\n",
    "\n",
    "**Review Text**: the body text of the review.\n",
    "\n",
    "**Rating**: the product score given by the customer from 1 (worst), to 5 (best).\n",
    "\n",
    "**Is it Recommended?**: the customers are asked whether or not they recommend the product. 1 means the product is recommended, 0 means not recommended.\n",
    "\n",
    "**Department**: the products are classified in different departments such as dress, top and ...\n",
    "\n",
    "A major part of this task is analysing the review text and deciding how positive or negative it is. To that end, there are two more data files: `positive-words.txt` and `negative-words.txt`, which contain lists of positive and negative words, respectively. These words come from the paper by *Minqing Hu and Bing Liu. \"Mining and summarizing customer reviews.\" Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, Seattle, Washington, USA, Aug 22-25, 2004*. You will need to invent a metric for how positive or negative \"Review Text\" is, based on how many of the words in it are in the positive/negative word lists. For instance, is a review containing one positive and one negative word: overall positive, negative or neutral? - try and develop a single measure based on the word occurrences that will describe the positivity/negativity of the review. You can also decide if a \"Title\" is positive, negative or neutral by searching for them in the lists of positive and negative words. Once you have developed one positivity/negativity measure can you think of other measures that you could compare?\n",
    "\n",
    "This project is open-ended, so you can come up with your own ideas to analyse the dataset and extract useful information or interesting facts. However at least one of the ideas you present should make use of the positive and negative word lists for analysing the reviews text. Here are some questions you might address in your analysis (of course you are not limited to just these questions):\n",
    "\n",
    "- What is the age distribution of customers?\n",
    "- What is the most popular item in each age group? (you can classify the ages however you think appropriate - be sure to justify what you do).\n",
    "- Using the measure of negativity or positivity that you define, rate the reviews. You can also decide whether a title is positive or negative. Are the negativity-positivity of the titles and that of the review texts correlated? \n",
    "- What is the average rating in positive, negative or neutral reviews?\n",
    "- Is the rating correlated to your measure of negativity-positivity? \n",
    "- Are there many outliers who wrote a negative text but left a high rating (or vice versa)?\n",
    "- Which product attracted the most positive reviews? This would help the company to focus more on the product that people liked or make changes to the product that people did not like. Is there any such advice you could give them on the products that could come from the reviews?\n",
    "- What is the most recommended product? What is the least recommended product?\n",
    "- Which group of reviewers wrote a longer text in their review? Do unhappy customers write longer reviews or satisfied customers? \n",
    "- Which age group uses more positive words? Which age group uses more negative words?\n",
    "- Are older people more inclined to recommend a product or younger people?\n",
    "- Is it true that unhappy customers use more capital letters? or it is the other way around?\n",
    "- Can you come up with a way to consider the positive words in a negative statement negative? For example, \"Not impressed or satisfied\" is a negative title, but if you just count the positive and negative words, you will find two positive words (\"impressed\" and \"satisfied\") and a negative word (\"not\"). Hence, just based on the word count, you might wrongly find the title to be positive. This might be easier for the titles, but you can also break down the review text to sentences and apply your method there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the modules:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re  \n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe5 in position 276: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe5 in position 276: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1dc974066ae5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#importing WomensApparelReviews.csv in notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# the csv file:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'WomensApparelReviews.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nrows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1996\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe5 in position 276: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "#importing WomensApparelReviews.csv in notebook \n",
    "# the csv file:\n",
    "df = pd.read_csv('WomensApparelReviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the age distribution of customers?\n",
    "data_age=df['Age']\n",
    "plt.hist(data_age)\n",
    "plt.title(\"the age distribution of customers\")\n",
    "plt.xlabel('the age group')\n",
    "plt.ylabel('the number of people')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#What is the most popular item in each age group?\n",
    "\n",
    "# NaN dropped:\n",
    "dq2=df.dropna(how='any')\n",
    "\n",
    "#from the UN World Health Organization we have a new age range:\n",
    "#young people under 44 years old\n",
    "d_young=dq2.loc[(dq2['Age']<=44),'Department']\n",
    "\n",
    "plt.hist(d_young)\n",
    "plt.title(\"the popular items in the age group which is below 44\")\n",
    "\n",
    "plt.xlabel('departments')\n",
    "plt.ylabel('the number of each items')\n",
    "plt.show()\n",
    "\n",
    "#middle-aged people between 45 and 59 years old\n",
    "d_middle=dq2.loc[(dq2['Age']>=45)&(dq2['Age']<=59),'Department']\n",
    "\n",
    "plt.hist(d_middle)\n",
    "plt.title(\"the popular items in the age group which is from 45 to 59\")\n",
    "plt.xlabel('departments')\n",
    "plt.ylabel('the number of each items')\n",
    "plt.show()\n",
    "\n",
    "#old people between 60 and 75 years old\n",
    "d_old=dq2.loc[(dq2['Age']>=60)&(dq2['Age']<=75),'Department']\n",
    "\n",
    "plt.hist(d_old)\n",
    "plt.title(\"the popular items in the age group which is from 60 to 75\")\n",
    "plt.xlabel('departments')\n",
    "plt.ylabel('the number of each items')\n",
    "plt.show()\n",
    "\n",
    "#and long-lived people over 75 years old.\n",
    "d_long=dq2.loc[(dq2['Age']>=76),'Department']\n",
    "\n",
    "plt.hist(d_long)\n",
    "plt.title(\"the popular items in the age group which is over 75\")\n",
    "plt.xlabel('departments')\n",
    "plt.ylabel('the number of each items')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the measure of negativity or positivity that you define, rate the reviews. \n",
    "d_measure=df[['Title','Review Text']]\n",
    "#clean d_measure ,such as change upper words into lower words and so on.\n",
    "import string\n",
    "d_measure['Title']= d_measure['Title'].str.lower()\n",
    "d_measure['Review Text']= d_measure['Review Text'].str.lower()\n",
    "string.punctuation\n",
    "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "d_measure['Title']= d_measure['Title'].str.replace(r'[^\\w\\s]+','')\n",
    "d_measure['Review Text']= d_measure['Review Text'].str.replace(r'[^\\w\\s]+','')\n",
    "\n",
    "d_measure['Review Text']\n",
    "\n",
    "#open negative-words.txt and positive-words.txt\n",
    "with open('positive-words.txt', 'r') as f:  \n",
    "    positive_words= f.readlines()\n",
    "with open('negative-words.txt', 'r') as g:\n",
    "    negative_words = g.readlines()\n",
    "positive_words1 = positive_words.copy()\n",
    "negative_words1 = negative_words.copy()\n",
    "# only have words for evaluation positive_words1/negative_words1\n",
    "\n",
    "for i in range (35):\n",
    "    positive_words1.remove(positive_words[i])\n",
    "    negative_words1.remove(negative_words[i])\n",
    "# delete blanks at the right of words\n",
    "for i in range (len(positive_words1)):\n",
    "    positive_words1[i] = positive_words1[i].rstrip()\n",
    "for i in range (len(negative_words1)):\n",
    "    negative_words1[i] = negative_words1[i].rstrip()\n",
    "x=d_measure['Review Text'].tolist()\n",
    "\n",
    "# the number of positive words\n",
    "def count_pos(x):\n",
    "    pos_num = 0\n",
    "    for i in x.split()  :\n",
    "        if i in positive_words1 :\n",
    "            pos_num += 1 \n",
    "    return pos_num\n",
    "\n",
    "# the number of negative words\n",
    "def count_neg(x):\n",
    "    neg_num = 0\n",
    "    for i in x.split()  :\n",
    "        if i in negative_words1 :\n",
    "            neg_num += 1 \n",
    "    return neg_num\n",
    "\n",
    "\n",
    "r=[]\n",
    "v=d_measure.shape[0]\n",
    "for i in range(v):\n",
    "    if type(x[i])==str:\n",
    "        n=count_pos(x[i])-count_neg(x[i])\n",
    "        r.append(n)\n",
    "    else:\n",
    "        r.append(0)\n",
    "d_measure = pd.DataFrame(columns=['rate'],data=r)\n",
    "d_measure.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the average rating in positive, negative or neutral reviews?\n",
    "#the average rating in positive reviews\n",
    "#the average rating in negative reviews\n",
    "df['rate']=d_measure\n",
    "d_positive=df.loc[(df['rate']>=3),'Rating']\n",
    "positiver=d_positive.mean()\n",
    "print('the average rating in positive reviews is')\n",
    "print(positiver)\n",
    "\n",
    "#the average rating in negative reviews\n",
    "d_negative=df.loc[(df['rate']<=-2),'Rating']\n",
    "negativer=d_negative.mean()\n",
    "print('the average rating in negative reviews is')\n",
    "print(negativer)\n",
    "\n",
    "#the average rating in neutral reviews\n",
    "d_neutral=df.loc[(df['rate']<=2)&(df['rate']>=-1),'Rating']\n",
    "neutralr=d_neutral.mean()\n",
    "print('the average rating in neutral reviews is')\n",
    "print(neutralr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the rating correlated to your measure of negativity-positivity\n",
    "#the rating correlated to the positive rate\n",
    "a=(df['rate']>=3).corr(df['Rating'])\n",
    "print('the  correlation between the rating and the positive rate is')\n",
    "print(round(a,2))\n",
    "#the rating correlated to the negative rate\n",
    "b=(df['rate']<=-2).corr(df['Rating'])\n",
    "print('the  correlation between the rating and the negative rate is')\n",
    "print(round(b,2))\n",
    "#the rating correlated to the neutral rate\n",
    "c=((df['rate']<=2)&(df['rate']>=-1)).corr(df['Rating'])\n",
    "print('the  correlation between the rating and the neutral rate is')\n",
    "print(round(c,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are there many outliers who wrote a negative text but left a high rating (or vice versa)?\n",
    "d_neghighrate=df.loc[(df['rate']<=-2)&(df['Rating']==5),'Review Text']\n",
    "print('This are outliers who wrote a negative text but left a high rating. Here are these people\\'s review text:')\n",
    "d_neghighrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which product attracted the most positive reviews?\n",
    "d_positiveproduct=df.loc[(df['rate']>=3),'Product ID']\n",
    "a=d_positiveproduct.value_counts()\n",
    "print(a)\n",
    "print('from above we can find product attracted the most positive reviews is 1078')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the most recommended product? What is the least recommended product?\n",
    "#Using the measure of negativity or positivity that you define, rate the reviews. \n",
    "d_measure=df[['Department','Rating']]\n",
    "#calculate the average rate of Tops\n",
    "d_measure1=d_measure[d_measure['Department']=='Tops']\n",
    "a1=d_measure1.shape[0]\n",
    "b1=sum(d_measure1['Rating'])\n",
    "c1=b1/a1\n",
    "#calculate the average rate of Dresses\n",
    "d_measure2=d_measure[d_measure['Department']=='Dresses']\n",
    "a2=d_measure2.shape[0]\n",
    "b2=sum(d_measure2['Rating'])\n",
    "c2=b2/a2\n",
    "#calculate the average rate of Intimate\n",
    "d_measure3=d_measure[d_measure['Department']=='Intimate']\n",
    "a3=d_measure3.shape[0]\n",
    "b3=sum(d_measure3['Rating'])\n",
    "c3=b3/a3\n",
    "#calculate the average rate of Bottoms\n",
    "d_measure4=d_measure[d_measure['Department']=='Bottoms']\n",
    "a4=d_measure4.shape[0]\n",
    "b4=sum(d_measure4['Rating'])\n",
    "c4=b4/a4\n",
    "#calculate the average rate of Jackets\n",
    "d_measure5=d_measure[d_measure['Department']=='Jackets']\n",
    "a5=d_measure5.shape[0]\n",
    "b5=sum(d_measure5['Rating'])\n",
    "c5=b5/a5\n",
    "#calculate the average rate of Trend\n",
    "d_measure6=d_measure[d_measure['Department']=='Trend']\n",
    "a6=d_measure6.shape[0]\n",
    "b6=sum(d_measure6['Rating'])\n",
    "c6=b6/a6\n",
    "if c1==max(c1,c2,c3,c4,c5,c6):\n",
    "    print('Tops is the most recommended product')\n",
    "if c2==max(c1,c2,c3,c4,c5,c6):\n",
    "    print('Dresses is the most recommended product')\n",
    "if c3==max(c1,c2,c3,c4,c5,c6):\n",
    "    print('Intimate is the most recommended product')\n",
    "if c4==max(c1,c2,c3,c4,c5,c6):\n",
    "    print('Bottoms is the most recommended product')\n",
    "if c5==max(c1,c2,c3,c4,c5,c6):\n",
    "    print('Jackets is the most recommended product')\n",
    "if c6==max(c1,c2,c3,c4,c5,c6):\n",
    "    print('Trend is the least recommended product')\n",
    "if c1==min(c1,c2,c3,c4,c5,c6):\n",
    "    print('Tops is the least recommended product')\n",
    "if c2==min(c1,c2,c3,c4,c5,c6):\n",
    "    print('Dresses is the least recommended product')\n",
    "if c3==min(c1,c2,c3,c4,c5,c6):\n",
    "    print('Intimate is the least recommended product')\n",
    "if c4==min(c1,c2,c3,c4,c5,c6):\n",
    "    print('Bottoms is the least recommended product')\n",
    "if c5==min(c1,c2,c3,c4,c5,c6):\n",
    "    print('Jackets is the least recommended product')\n",
    "if c6==min(c1,c2,c3,c4,c5,c6):\n",
    "    print('Trend is the least recommended product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which group of reviewers wrote a longer text in their review?\n",
    "#Using the measure of negativity or positivity that you define, rate the reviews. \n",
    "d_measure=df[['Rating','Review Text']]\n",
    "#clean d_measure ,such as change upper words into lower words and so on.\n",
    "import string\n",
    "d_measure['Review Text']= d_measure['Review Text'].str.lower()\n",
    "string.punctuation\n",
    "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "d_measure['Review Text']= d_measure['Review Text'].str.replace(r'[^\\w\\s]+','')\n",
    "\n",
    "dq2=d_measure.dropna(how='any')\n",
    "\n",
    "#from the UN World Health Organization we have a new age range:\n",
    "#young people under 44 years old\n",
    "d_unhappy=dq2.loc[(dq2['Rating']<=3),'Review Text']\n",
    "d_satisfied=dq2.loc[(dq2['Rating']>3),'Review Text']\n",
    "#calculate the average words of two groups\n",
    "a=len(d_unhappy)\n",
    "b=len(d_satisfied)\n",
    "x=d_unhappy.tolist()\n",
    "y=d_satisfied.tolist()\n",
    "k=0\n",
    "l=0\n",
    "for i in range(a):\n",
    "    k=k+len(x[i].split())\n",
    "for j in range(b):\n",
    "    l=l+len(y[i].split())\n",
    "average_unhappy=k/a\n",
    "average_satisfied=l/b\n",
    "if average_unhappy>average_satisfied:\n",
    "    print('unhappy customers write longer reviews')\n",
    "else:\n",
    "    print('satisfied customers write longer reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which age group uses more positive words? Which age group uses more negative words?\n",
    "#Using the measure of negativity or positivity that you define, rate the reviews. \n",
    "d_measure=df[['Age','Review Text']]\n",
    "#clean d_measure ,such as change upper words into lower words and so on.\n",
    "import string\n",
    "d_measure['Review Text']= d_measure['Review Text'].str.lower()\n",
    "string.punctuation\n",
    "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "d_measure['Review Text']= d_measure['Review Text'].str.replace(r'[^\\w\\s]+','')\n",
    "\n",
    "dq2=d_measure.dropna(how='any')\n",
    "\n",
    "#young people under 44 years old\n",
    "d_young=dq2.loc[(dq2['Age']<=44),'Review Text']\n",
    "#middle-aged people between 45 and 59 years old\n",
    "d_middle=dq2.loc[(dq2['Age']>=45)&(dq2['Age']<=59),'Review Text']\n",
    "#old people between 60 and 75 years old\n",
    "d_old=dq2.loc[(dq2['Age']>=60)&(dq2['Age']<=75),'Review Text']\n",
    "#and long-lived people over 75 years old.\n",
    "d_long=dq2.loc[(dq2['Age']>=76),'Review Text']\n",
    "\n",
    "#calculate the average negative words of four groups\n",
    "a=len(d_young)\n",
    "b=len(d_middle)\n",
    "c=len(d_old)\n",
    "d=len(d_long)\n",
    "x=d_young.tolist()\n",
    "y=d_middle.tolist()\n",
    "z=d_old.tolist()\n",
    "r=d_long.tolist()\n",
    "k=0\n",
    "l=0\n",
    "p=0\n",
    "q=0\n",
    "for i in range(a):\n",
    "    if type(x[i])==str:\n",
    "        k=k+count_pos(x[i])\n",
    "    else:\n",
    "        k=k\n",
    "for i in range(b):\n",
    "    if type(y[i])==str:\n",
    "        l=l+count_pos(y[i])\n",
    "    else:\n",
    "        l=l\n",
    "for i in range(c):\n",
    "    if type(z[i])==str:\n",
    "        p=p+count_pos(z[i])\n",
    "    else:\n",
    "        p=p\n",
    "for i in range(d):\n",
    "    if type(r[i])==str:\n",
    "        q=q+count_pos(r[i])\n",
    "    else:\n",
    "        q=q\n",
    "\n",
    "average_young=k/a\n",
    "average_middle=l/b\n",
    "average_old=p/c\n",
    "average_long=q/d\n",
    "if average_young==max(average_young,average_middle,average_old,average_long):\n",
    "    print('young people write most positive words')\n",
    "elif average_middle==max(average_young,average_middle,average_old,average_long):\n",
    "    print('middle aged people write most positive words')\n",
    "elif average_old==max(average_young,average_middle,average_old,average_long):\n",
    "    print('old people write most positive words')\n",
    "elif average_long==max(average_young,average_middle,average_old,average_long):\n",
    "    print('long old people write most positive words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are older people more inclined to recommend a product or younger people?\n",
    "d_young11=df.loc[(df['Age']<=49),'Is it Recommended?']\n",
    "x=d_young11.value_counts()\n",
    "d_old11=df.loc[(df['Age']>=50),'Is it Recommended?']\n",
    "y=d_old11.value_counts()\n",
    "\n",
    "#the percentage of young people who make recommend\n",
    "a=x[1]/len(d_young11)\n",
    "print('the percentage of young people who make recommend is')\n",
    "print(round(a,2))\n",
    "\n",
    "#the percentage of old people who make recommend\n",
    "b=y[1]/len(d_old11)\n",
    "print('the percentage of old people who make recommend is')\n",
    "print(round(b,2))\n",
    "\n",
    "#compare the percentage of young people and old people who make recommends\n",
    "if a>b:\n",
    "    print('younger people more inclined to recommend a product')\n",
    "else:\n",
    "    print('older people more inclined to recommend a product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 2 - Analysing transportation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you should analysing the cycling trips in Edinburgh in September 2019 collected in `cyclingtrips_Sep2019.csv`. This dataset is kindly supplied for use by Edinburgh Cycle Hire under the [Open Government License (OGL) v3.0](https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/). You can extend your analysis to other months by downloading data from [this link](https://edinburghcyclehire.com/open-data/historical). \n",
    "\n",
    "As a part of this task you should visualise some aspects of the data geographically on a map. There are several different libraries and packages that you can use for this purpose. Below, I walk you through the installation and the basic usage of **folium**, but you are welcome to use any other geographical visualisation tools like `googlemaps` and `gmplot`. You can also find more about the folium library [here](https://python-visualization.github.io/folium/) and implement more advanced features of it in your project.\n",
    "\n",
    "First, you need to install the library before importing it. The following cell does it for you in `Noteable` or a regular `Jupyter Notebook`:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you installed folium, you should import it and give it a starting coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[55.924550, -3.176920],\n",
    "    zoom_start=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, I gave the latitude and longitude of Murchison House as the starting location to folium. I also set the initial zoom to 15. You can change this coordinate as well as the zooming and observe the results. To display the map in a Jupyter notebook, you just need to ask for the object representation (simply typing `\"m\"` for the above map):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can mark the Murchison House on the map by a circle with `radius=50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.CircleMarker(\n",
    "    location=[55.924550, -3.176920],\n",
    "    radius=50,\n",
    "    color='blue',\n",
    "    fill=True,\n",
    "    fill_color='blue'\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this tool, we want to visualise how busy the stations are as destinations or starting points of cycling trips. After dividing the cycling trips into morning and afternoon/evening trips, show how many of them end in or start from a particular station. You can do this by drawing a radius proportional to the number of trips. You can also separate the stations as destinations or starting points by drawing them on different maps or by colour-coding them.\n",
    "\n",
    "Just like the first task, this is an open-ended problem. You can address the following or any other interesting questions about bike trips:\n",
    "\n",
    "- What was the average journey time and distance of bike trips on weekdays? What about weekends?\n",
    "- What was the most common time(s) of day for journeys to be undertaken?\n",
    "- Which areas do you suggest for building the new stations based on your analysis?\n",
    "- Can you visualise which stations were used mostly for shorter trips and which one for longer trips?\n",
    "- Can you compare the statistics of different months in summer? Is there any remarkable difference between them?\n",
    "\n",
    "There is more open data available for other cities - here is the link for the data on the similar bike hire scheme in London ([TFL open data](https://cycling.data.tfl.gov.uk)), and for New York [here](https://www.citibikenyc.com/system-data). You could also think about some of the issues involved in other cities and bike share schemes, and perform similar sorts of analyses or comparisons. For example:\n",
    "\n",
    "- Do bike hire schemes share popular times of day?\n",
    "- Can you trace the common commute patterns of different cities? Are there any commonalities of shape or structure to the patterns?\n",
    "- How does the average rental time compare across different cities? How does that time change as the size of the city changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
